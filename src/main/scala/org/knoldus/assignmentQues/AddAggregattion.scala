package org.knoldus.assignmentQues

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions.{col, count}

object AddAggregattion extends App {
  val spark = SparkSession.builder()
    .appName("Add Aggregation To Column")
    .master("local[1]")
    .getOrCreate()

  import spark.implicits._
  val input = Seq(
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604900", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604899", "10.0.0.2.54880", "10.0.0.3.5001", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2),
    ("05:49:56.604908", "10.0.0.3.5001", "10.0.0.2.54880", 2)).toDF("column0", "column1", "column2", "label")

  val windowSpec = Window.partitionBy(col("column1"), col("column2")).orderBy(col("column1").desc)
  input.withColumn("count",count("column1").over(windowSpec)).show(false)

}
